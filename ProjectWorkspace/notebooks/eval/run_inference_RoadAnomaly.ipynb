{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1SXvusMPL5RHqnuZFmml5yDugTV4Qcys8","authorship_tag":"ABX9TyM+yuhQhVMSimjBfY78Hsmj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"F1JFmYz9VJGK"},"outputs":[],"source":["#===============================================================\n","# DEBUG TOGGLE SWITCH\n","def d(*args, **kwargs):\n","    if d.ON:\n","        print(*args, **kwargs)\n","d.ON = True\n","#===============================================================\n","\n","#================================================\n","if __name__ == \"__main__\":\n","  try:\n","    import segmentation_models_pytorch as smp\n","  except ImportError:\n","    !pip install -q segmentation_models_pytorch timm\n","    import segmentation_models_pytorch as smp\n","#============================================================0\n","\n","#=============================================================\n","import os\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torchvision import transforms as T\n","from PIL import Image\n","from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, roc_auc_score, roc_curve\n","import pandas as pd\n","from tqdm import tqdm\n","#===================================================================\n","\n","\n","#=====================================================================00\n","# PATHS SETTING\n","root_dir = \"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection\"\n","frames_dir = os.path.join(root_dir, \"Datasets/RoadAnomaly_jpg\")\n","split_file = os.path.join(root_dir, \"ProjectWorkspace/splits/roadAnomaly_valid_pairs.txt\")\n","ckpt_path = os.path.join(root_dir, \"ProjectWorkspace/ckpts/updated_loss_model.pth\")\n","lambda_path = os.path.join(root_dir, \"ProjectWorkspace/src/eval/lambda_hat_3rdattempt.txt\")\n","output_csv = os.path.join(root_dir, \"ProjectWorkspace/eval/roadAnomaly_metrics.csv\")\n","#================================================================================0\n","\n","#==================================================================================\n","# NAVIGATION TO GET TO THE FOLDER WITH STUFF INSIDE\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/ProjectWorkspace/src\")\n","\n","#==============================================================================\n","# MODEL LOADING\n","from network.deeplab_dualhead import get_model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = get_model().to(device)\n","model.load_state_dict(torch.load(ckpt_path, map_location = device))\n","model.eval()\n","#=================================================================================\n","\n","#================================================================================\n","# CALIB LOADING\n","with open(lambda_path, \"r\") as f:\n","    lambda_hat = float(f.read().strip())\n","d(f\"Loaded lambda_hat = {lambda_hat}\")\n","#===================================================================================\n","\n","\n","#===================================================================================\n","# PREPROCESSING\n","transform = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225])\n","])\n","#==================================================================================0\n","\n","\n","#======================================================================\n","# INFERENCE\n","threshold_objectness = 0.51\n","results = []\n","all_gt_pixels = []\n","all_scores = []\n","\n","with open(split_file, \"r\") as f:\n","  rel_paths = f.read().splitlines()\n","\n","for rel_path in tqdm(rel_paths):\n","  rgb_path = os.path.join(frames_dir, rel_path)\n","  label_path = rgb_path.replace(\".jpg\", \".labels/labels_semantic.png\")\n","\n","  rgb_img = Image.open(rgb_path).convert(\"RGB\")\n","  input_tensor = transform(rgb_img).unsqueeze(0).to(device)\n","\n","  with torch.no_grad():\n","    seg_logits, obj_logits = model(input_tensor)\n","    seg_logits = F.interpolate(seg_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","    obj_logits = F.interpolate(obj_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","\n","    softmax = torch.softmax(seg_logits, dim=1)\n","    objectness = torch.sigmoid(obj_logits)\n","\n","    conf_score, _ = torch.max(softmax, dim=1)\n","    nonconformity = 1.0 - conf_score\n","    unknown_mask = (nonconformity > lambda_hat).squeeze(0).cpu().numpy()\n","    object_mask = (objectness > threshold_objectness).squeeze().cpu().numpy()\n","    obstacle_mask = (unknown_mask & object_mask).astype(np.uint8)\n","    obstacle_score = objectness.squeeze().cpu().numpy() * nonconformity.squeeze().cpu().numpy()\n","\n","  gt_mask = np.array(Image.open(label_path))\n","  gt_anomaly = (gt_mask == 2).astype(np.uint8)\n","\n","  pred_flat = obstacle_mask.flatten()\n","  gt_flat = gt_anomaly.flatten()\n","  score_flat = obstacle_score.flatten()\n","\n","  precision = precision_score(gt_flat, pred_flat, zero_division=0)\n","  recall = recall_score(gt_flat, pred_flat, zero_division=0)\n","  f1 = f1_score(gt_flat, pred_flat, zero_division=0)\n","  iou = jaccard_score(gt_flat, pred_flat, zero_division=0)\n","\n","  results.append({\n","      \"image\": rel_path,\n","      \"precision\": precision,\n","      \"recall\": recall,\n","      \"f1\": f1,\n","      \"iou\": iou\n","  })\n","\n","  all_gt_pixels.append((rel_path, gt_flat))\n","  all_scores.append((rel_path, score_flat))\n","\n","df = pd.DataFrame(results)\n","df.to_csv(output_csv, index=False)\n","d(f\"Saved metrics to {output_csv}\")\n","#=============================================================================\n","\n","\n","#===========================================================================0\n","# AGGREGATED METRICS â€” FULL vs. TRIMMED\n","metrics = [\"precision\", \"recall\", \"f1\", \"iou\"]\n","\n","# GLOBAL\n","global_stats = df[metrics].agg([\"mean\", \"std\", \"min\", \"max\", \"median\"])\n","d(\"\\n== GLOBAL METRICS (all images) ==\")\n","d(global_stats)\n","\n","all_gt_pixels_full = np.concatenate([x for (_, x) in all_gt_pixels])\n","all_scores_full = np.concatenate([x for (_, x) in all_scores])\n","\n","auroc = roc_auc_score(all_gt_pixels_full, all_scores_full)\n","fpr, tpr, thresholds = roc_curve(all_gt_pixels_full, all_scores_full)\n","fpr95 = fpr[np.argmax(tpr >= 0.95)]\n","\n","d(f\"\\n== GLOBAL SCORE-BASED METRICS ==\")\n","d(f\"AUROC = {auroc:.6f}\")\n","d(f\"FPR@95TPR = {fpr95:.6f}\")\n","#==============================================================================\n","\n","\n","alpha = 0.15\n","lower_q = df[\"iou\"].quantile(alpha)\n","upper_q = df[\"iou\"].quantile(1 - alpha)\n","df_trimmed = df[(df[\"iou\"] > lower_q) & (df[\"iou\"] < upper_q)]\n","\n","d(f\"== TRIMMED METRICS (middle {int((1 - 2 * alpha)*100)}% samples) ==\")\n","trimmed_stats = df_trimmed[metrics].agg([\"mean\", \"std\", \"min\", \"max\", \"median\"])\n","d(trimmed_stats)\n","\n","trimmed_image_names = set(df_trimmed[\"image\"])\n","trimmed_gt_pixels = []\n","trimmed_scores = []\n","\n","for name, gt in all_gt_pixels:\n","    if name in trimmed_image_names:\n","        trimmed_gt_pixels.append(gt)\n","\n","for name, score in all_scores:\n","    if name in trimmed_image_names:\n","        trimmed_scores.append(score)\n","\n","trimmed_gt_pixels = np.concatenate(trimmed_gt_pixels)\n","trimmed_scores = np.concatenate(trimmed_scores)\n","\n","# AUROC + FPR@95TPR\n","auroc_trimmed = roc_auc_score(trimmed_gt_pixels, trimmed_scores)\n","fpr_t, tpr_t, _ = roc_curve(trimmed_gt_pixels, trimmed_scores)\n","fpr95_trimmed = fpr_t[np.argmax(tpr_t >= 0.95)]\n","\n","d(f\"== TRIMMED SCORE-BASED METRICS (middle {int((1 - 2 * alpha)*100)}% samples) ==\")\n","d(f\"AUROC = {auroc_trimmed:.6f}\")\n","d(f\"FPR@95TPR = {fpr95_trimmed:.6f}\")\n","\n","\n","#=====================================================================\n","\n"]},{"cell_type":"code","source":["#============================================================\n","# DISPLAY PREDICTIONS FOR PRESENTATION\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","save_outputs = True # toggling until they're good to be saved\n","\n","metrics_df = pd.read_csv(output_csv)\n","\n","alpha = 0.15\n","q_low = metrics_df[\"iou\"].quantile(alpha)\n","q_high = metrics_df[\"iou\"].quantile(1 - alpha)\n","\n","top_samples = set(metrics_df[metrics_df[\"iou\"] > q_high][\"image\"])\n","worst_samples = set(metrics_df[metrics_df[\"iou\"] < q_low][\"image\"])\n","middle_samples = set(metrics_df[(metrics_df[\"iou\"] >= q_low) & (metrics_df[\"iou\"] <= q_high)][\"image\"])\n","\n","\n","save_dir_root = os.path.join(root_dir, \"ProjectWorkspace/eval/RoadAnomalyInferenceImages\")\n","save_top_root = os.path.join(save_dir_root, \"TopSamples\")\n","save_worst_root = os.path.join(save_dir_root, \"WorstSamples\")\n","\n","os.makedirs(save_dir_root, exist_ok=True)\n","os.makedirs(save_top_root, exist_ok=True)\n","os.makedirs(save_worst_root, exist_ok=True)\n","\n","for sample in results:\n","  rel_path = sample[\"image\"]\n","  rgb_path = os.path.join(frames_dir, rel_path)\n","  label_path = rgb_path.replace(\".jpg\", \".labels/labels_semantic.png\")\n","  name = os.path.splitext(os.path.basename(rgb_path))[0]\n","\n","  is_top = rel_path in top_samples\n","  is_worst = rel_path in worst_samples\n","  is_middle = rel_path in middle_samples\n","\n","  should_save = save_outputs\n","  if rel_path in top_samples:\n","    save_dir = os.path.join(save_top_root, name)\n","  elif rel_path in worst_samples:\n","      save_dir = os.path.join(save_worst_root, name)\n","  elif rel_path in middle_samples:\n","      save_dir = os.path.join(save_dir_root, name)\n","  else:\n","      continue  # shouldn't happen\n","\n","\n","  rgb_img = Image.open(rgb_path).convert(\"RGB\")\n","\n","  gt_mask = np.array(Image.open(label_path))\n","  gt_anomaly = (gt_mask == 2).astype(np.uint8)\n","\n","  input_tensor = transform(rgb_img).unsqueeze(0).to(device)\n","  with torch.no_grad():\n","      seg_logits, obj_logits = model(input_tensor)\n","      seg_logits = F.interpolate(seg_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","      obj_logits = F.interpolate(obj_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","      softmax = torch.softmax(seg_logits, dim=1)\n","      objectness = torch.sigmoid(obj_logits)\n","      conf_score, _ = torch.max(softmax, dim=1)\n","      nonconformity = 1.0 - conf_score\n","      unknown_mask = (nonconformity > lambda_hat).squeeze(0).cpu().numpy()\n","      object_mask = (objectness > threshold_objectness).squeeze().cpu().numpy()\n","      obstacle_mask = (unknown_mask & object_mask).astype(np.uint8)\n","      conf_map = conf_score.squeeze().cpu().numpy()\n","      obstacle_score = (objectness.squeeze().cpu().numpy()) * (nonconformity.squeeze().cpu().numpy())\n","\n","\n","  # VISUAL DISPLAY (always)\n","  fig, axs = plt.subplots(1, 7, figsize=(42, 6))\n","  axs[0].imshow(rgb_img)\n","  axs[0].set_title(\"RGB Image\")\n","  axs[1].imshow(gt_anomaly, cmap=\"gray\")\n","  axs[1].set_title(\"GT Anomaly\")\n","  axs[2].imshow(unknown_mask, cmap=\"gray\")\n","  axs[2].set_title(\"Unknown Mask\")\n","  axs[3].imshow(object_mask, cmap=\"gray\")\n","  axs[3].set_title(\"Objectness Mask\")\n","  axs[4].imshow(obstacle_mask, cmap=\"gray\")\n","  axs[4].set_title(\"Obstacle = Unknown AND Object\")\n","\n","  # CONFIDENCE MAP USING ONLY SOFTMAX\n","  im1 = axs[5].imshow(conf_map, cmap=\"viridis\", vmin=0.0, vmax=1.0)\n","  axs[5].set_title(\"Confidence Map (Max Softmax)\")\n","  cbar1 = fig.colorbar(im1, ax=axs[5], fraction=0.046, pad=0.04)\n","  cbar1.set_label(\"Confidence scale\")\n","  # CONFIDENCE MAP USING SOFTMAX AND SIGMOID HEAD COMBINED\n","  im2 = axs[6].imshow(obstacle_score, cmap=\"viridis_r\", vmin=0.0, vmax=1.0)  #doing viridis\"_r\" in order to revert the behaviour of the viridis heatmap and return an image prone to be compared to the other confidence map\n","  axs[6].set_title(\"Obstacle Score = Objectness combined with Nonconformity\")\n","  cbar2 = fig.colorbar(im2, ax=axs[6], fraction=0.046, pad=0.04)\n","  cbar2.set_label(\"Obstacle Score\")\n","\n","  for ax in axs:\n","      ax.axis(\"off\")\n","  plt.suptitle(name, fontsize=18)\n","  plt.tight_layout()\n","  plt.show()\n","\n","  # PER-IMAGE SAVING (only if save_outputs and in top samples)\n","  if should_save:\n","      os.makedirs(save_dir, exist_ok=True)\n","      rgb_img.save(os.path.join(save_dir, \"rgb.png\"))\n","\n","      #Softmax confidence map saving\n","      fig, ax = plt.subplots(figsize=(6, 5))\n","      im = ax.imshow(conf_map, cmap=\"viridis\", vmin=0.0, vmax=1.0)\n","      ax.axis(\"off\")\n","      cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","      cbar.set_label(\"Confidence scale\")\n","      plt.savefig(os.path.join(save_dir, \"confidence_map.png\"), dpi=200)\n","      plt.close()\n","\n","      #Softmax and sigmoid confidence map saving\n","      fig, ax = plt.subplots(figsize=(6, 5))\n","      im = ax.imshow(obstacle_score, cmap=\"viridis_r\", vmin=0.0, vmax=1.0)\n","      ax.axis(\"off\")\n","      cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","      cbar.set_label(\"Obstacle Score\")\n","      plt.savefig(os.path.join(save_dir, \"obstacle_score.png\"), dpi=200)\n","      plt.close()\n","\n","      if is_middle: #additional masks only for middle samples\n","        Image.fromarray((gt_anomaly * 255).astype(np.uint8)).save(os.path.join(save_dir, \"gt_anomaly.png\"))\n","        Image.fromarray((unknown_mask * 255).astype(np.uint8)).save(os.path.join(save_dir, \"unknown_mask.png\"))\n","        Image.fromarray((object_mask * 255).astype(np.uint8)).save(os.path.join(save_dir, \"object_mask.png\"))\n","        Image.fromarray((obstacle_mask * 255).astype(np.uint8)).save(os.path.join(save_dir, \"obstacle_mask.png\"))\n","#===============================================================\n"],"metadata":{"id":"cO6wb1V8dusd","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TaDdpLvpFqKd5mu6XxvRVuLpucVWmoRU"},"executionInfo":{"status":"ok","timestamp":1753011776460,"user_tz":-120,"elapsed":181211,"user":{"displayName":"Francesco Maria GERMANO","userId":"08944067668830872995"}},"outputId":"a46f410d-9031-41ce-8dfa-1e071ee429f8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}