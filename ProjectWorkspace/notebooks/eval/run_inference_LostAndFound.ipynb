{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LPrymvEPsw6y"},"outputs":[],"source":["#===============================================================\n","# DEBUG TOGGLE SWITCH\n","def d(*args, **kwargs):\n","    if d.ON:\n","        print(*args, **kwargs)\n","d.ON = True\n","#===============================================================\n","\n","#================================================\n","if __name__ == \"__main__\":\n","  try:\n","    import segmentation_models_pytorch as smp\n","  except ImportError:\n","    !pip install -q segmentation_models_pytorch timm\n","    import segmentation_models_pytorch as smp\n","#============================================================0\n","\n","#===============================================================\n","# IMPORTS\n","import os\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from PIL import Image\n","import pandas as pd\n","from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, roc_auc_score, roc_curve\n","from torchvision import transforms as T\n","from tqdm import tqdm\n","import random\n","#=================================================================================================================\n","\n","\n","\n","\n","#=====================================================================================================================\n","# PATHS SETUP\n","root_dir = \"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection\"\n","frames_dir = os.path.join(root_dir, \"Datasets/LostAndFound/leftImg8bit/test\")\n","gt_dir = os.path.join(root_dir, \"Datasets/LostAndFound/gtCoarse/test\")\n","split_file = os.path.join(root_dir, \"ProjectWorkspace/splits/lostAndFound_splits_clean.txt\")\n","ckpt_path = os.path.join(root_dir, \"ProjectWorkspace/ckpts/updated_loss_model.pth\")\n","lambda_path = os.path.join(root_dir, \"ProjectWorkspace/src/eval/lambda_hat_3rdattempt.txt\")\n","output_csv = os.path.join(root_dir, \"ProjectWorkspace/eval/lostAndFound_metrics.csv\")\n","#=====================================================================================================\n","\n","#==================================================================================\n","# NAVIGATION TO GET TO THE FOLDER WITH STUFF INSIDE\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/ProjectWorkspace/src\")\n","\n","#==============================================================================\n","# MODEL LOADING\n","from network.deeplab_dualhead import get_model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = get_model().to(device)\n","model.load_state_dict(torch.load(ckpt_path, map_location = device))\n","model.eval()\n","#=================================================================================\n","\n","\n","\n","#==============================================================\n","# CALIB LOADING\n","with open(lambda_path, \"r\") as f:\n","  lambda_hat = float(f.read().strip())\n","d(f\"Loaded lambda_hat = {lambda_hat}\")\n","#===============================================================\n","\n","#===================================================================================\n","# PREPROCESSING\n","transform = T.Compose([\n","    T.ToTensor(),\n","    T.Normalize(mean=[0.485, 0.456, 0.406],\n","                std=[0.229, 0.224, 0.225])\n","])\n","#==================================================================================0\n","\n","\n","#===================================================================================\n","# INFERENCE\n","threshold_objectness = 0.51\n","results = []\n","all_gt_pixels = []\n","all_scores = []\n","\n","min_pixels = 200 #EDIT: since the dataset is for several purposes, they added some very far obstacles (can't even see them they're at the vanishing point)\n","skipped_small_gt = 0\n","\n","with open(split_file, \"r\") as f:\n","  rel_paths = f.read().splitlines()\n","\n","for rel_path in tqdm(rel_paths):\n","  rgb_path = os.path.join(frames_dir, rel_path + \"_leftImg8bit.png\")\n","  label_path = os.path.join(gt_dir, rel_path + \"_gtCoarse_labelIds.png\")\n","\n","  rgb_img = Image.open(rgb_path).convert(\"RGB\")\n","  input_tensor = transform(rgb_img).unsqueeze(0).to(device)\n","\n","  with torch.no_grad():\n","    seg_logits, obj_logits = model(input_tensor)\n","    seg_logits = F.interpolate(seg_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","    obj_logits = F.interpolate(obj_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","\n","    softmax = torch.softmax(seg_logits, dim=1)\n","    objectness = torch.sigmoid(obj_logits)\n","\n","    conf_score, _ = torch.max(softmax, dim=1)\n","    nonconformity = 1.0 - conf_score\n","    unknown_mask = (nonconformity > lambda_hat).squeeze(0).cpu().numpy()\n","    object_mask = (objectness > threshold_objectness).squeeze().cpu().numpy()\n","    obstacle_mask = (unknown_mask & object_mask).astype(np.uint8)\n","    obstacle_score = (objectness.squeeze().cpu().numpy()) * (nonconformity.squeeze().cpu().numpy())\n","\n","  hazard_ids = list(range(2, 44)) # from 2 to 43, doesn't take 44\n","  gt_mask = np.array(Image.open(label_path))\n","  gt_obstacle = np.isin(gt_mask, hazard_ids).astype(np.uint8)\n","\n","  num_gt = np.sum(gt_obstacle)\n","  if num_gt < min_pixels:\n","    skipped_small_gt += 1\n","    continue\n","\n","  pred_flat = obstacle_mask.flatten()\n","  gt_flat = gt_obstacle.flatten()\n","  score_flat = obstacle_score.flatten()\n","\n","  precision = precision_score(gt_flat, pred_flat, zero_division=0)\n","  recall = recall_score(gt_flat, pred_flat, zero_division=0)\n","  f1 = f1_score(gt_flat, pred_flat, zero_division=0)\n","  iou = jaccard_score(gt_flat, pred_flat, zero_division=0)\n","\n","  results.append({\n","      \"image\": rel_path,\n","      \"precision\": precision,\n","      \"recall\": recall,\n","      \"f1\": f1,\n","      \"iou\": iou\n","  })\n","\n","\n","  all_gt_pixels.append(gt_flat)\n","  all_scores.append(score_flat)\n","\n","df = pd.DataFrame(results)\n","df.to_csv(output_csv, index=False)\n","d(f\"Saved metrics to {output_csv}\")\n","print(f\"Total skipped images due to small GT obstacles or totally absent: {skipped_small_gt}\")\n","#================================================================================0\n","\n","\n","#=================================================================================\n","# GLOBAL AGGREGATED METRICS\n","metrics = [\"precision\", \"recall\", \"f1\", \"iou\"]\n","global_stats = df[metrics].agg([\"mean\", \"std\", \"min\", \"max\", \"median\"])\n","print(\"\\n== AGGREGATED METRICS ==\")\n","print(global_stats)\n","#========================================================================================\n","\n","\n","\n","#=================================================================================================\n","# GLOBAL SCORE-BASED METRICS (Filtered Random Subset to avoid OOM)\n","filtered_entries = [\n","    (gt, sc) for (gt, sc) in zip(all_gt_pixels, all_scores)\n","    if np.sum(gt) >= min_pixels\n","]\n","\n","random.shuffle(filtered_entries)\n","subset_size = 200  # reduce memory load\n","filtered_entries = filtered_entries[:subset_size]\n","\n","if len(filtered_entries) > 0:\n","    sampled_gt = np.concatenate([gt for gt, _ in filtered_entries])\n","    sampled_score = np.concatenate([sc for _, sc in filtered_entries])\n","\n","    auroc = roc_auc_score(sampled_gt, sampled_score)\n","    fpr, tpr, _ = roc_curve(sampled_gt, sampled_score)\n","    fpr95 = fpr[np.argmax(tpr >= 0.95)]\n","\n","    print(\"\\n== GLOBAL SCORE-BASED METRICS (Filtered Subset) ==\")\n","    print(f\"AUROC = {auroc:.6f}\")\n","    print(f\"FPR@95TPR = {fpr95:.6f}\")\n","else:\n","    print(\"\\n[WARNING] No valid samples found for AUROC/FPR95 computation.\")\n","#==================================================================================================\n","\n","\n","# FOR PRESENTATION\n","q_worst = df[\"iou\"].quantile(0.30)\n","q_top = df[\"iou\"].quantile(0.90)\n","\n","worst_samples = set(df[df[\"iou\"] <= q_worst][\"image\"])\n","top_samples = set(df[df[\"iou\"] >= q_top][\"image\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kH4KENdERx7s","collapsed":true},"outputs":[],"source":["#===============================================================================================\n","# DISPLAY PREDICTIONS FOR PRESENTATION (same as RoadAnomaly, just gonna change the directory names)\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","save_outputs = True # toggling until they're good to be saved\n","\n","# Load CSV of per-image metrics\n","metrics_df = pd.read_csv(output_csv)\n","\n","# Sort by IoU (assuming column name is 'iou' and image column is 'image')\n","sorted_df = metrics_df.sort_values(by='iou', ascending=False).reset_index(drop=True)\n","\n","# Extract file paths\n","top_samples = set(sorted_df.iloc[:10][\"image\"])\n","worst_samples = set(sorted_df.iloc[-10:][\"image\"])\n","middle_pool = sorted_df.iloc[10:-10][\"image\"].tolist()\n","\n","# Sample 20 randomly from the middle pool\n","random.seed(42)  # for reproducibility\n","middle_samples = set(random.sample(middle_pool, 20))\n","\n","# Set of samples to actually save\n","selected_samples = top_samples.union(worst_samples).union(middle_samples)\n","\n","save_dir_root = os.path.join(root_dir, \"ProjectWorkspace/eval/LostAndFoundInferenceImages\")\n","save_top_root = os.path.join(save_dir_root, \"TopResults\")\n","save_worst_root = os.path.join(save_dir_root, \"WorstResults\")\n","os.makedirs(save_dir_root, exist_ok=True)\n","os.makedirs(save_top_root, exist_ok=True)\n","os.makedirs(save_worst_root, exist_ok=True)\n","\n","\n","for sample in results:\n","    rel_path = sample[\"image\"]\n","    rgb_path = os.path.join(frames_dir, rel_path + \"_leftImg8bit.png\")\n","    label_path = os.path.join(gt_dir, rel_path + \"_gtCoarse_labelIds.png\")\n","    name = os.path.basename(rel_path)\n","\n","    is_top = rel_path in top_samples\n","    is_worst = rel_path in worst_samples\n","    should_save = save_outputs and (rel_path in selected_samples)\n","\n","    # DEBUG: informazioni di base\n","    d(\"→ Processing:\", rel_path)\n","    d(\"   is_top:\", is_top, \"is_worst:\", is_worst)\n","    d(\"   selected_samples contains rel_path:\", rel_path in selected_samples)\n","    d(\"   should_save:\", should_save)\n","    d(\"   RGB exists:\", os.path.exists(rgb_path))\n","    d(\"   LABEL exists:\", os.path.exists(label_path))\n","\n","    if not os.path.exists(rgb_path) or not os.path.exists(label_path):\n","        d(\"Missing files for\", rel_path)\n","        continue\n","\n","    rgb_img = Image.open(rgb_path).convert(\"RGB\")\n","\n","    hazard_ids = list(range(2, 44))  # Class IDs from 2 to 43 inclusive\n","    gt_mask = np.array(Image.open(label_path))\n","    gt_obstacle = np.isin(gt_mask, hazard_ids).astype(np.uint8)\n","    pixel_count = np.sum(gt_obstacle)\n","    d(\"   GT Obstacle pixel count:\", pixel_count)\n","\n","    if pixel_count < min_pixels:\n","        d(\"Skipping due to insufficient GT pixels\")\n","        continue\n","\n","    input_tensor = transform(rgb_img).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        seg_logits, obj_logits = model(input_tensor)\n","        seg_logits = F.interpolate(seg_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","        obj_logits = F.interpolate(obj_logits, size=rgb_img.size[::-1], mode=\"bilinear\", align_corners=False)\n","\n","        softmax = torch.softmax(seg_logits, dim=1)\n","        objectness = torch.sigmoid(obj_logits)\n","        conf_score, _ = torch.max(softmax, dim=1)\n","        nonconformity = 1.0 - conf_score\n","\n","        unknown_mask = (nonconformity > lambda_hat).squeeze(0).cpu().numpy()\n","        object_mask = (objectness > threshold_objectness).squeeze().cpu().numpy()\n","        obstacle_mask = (unknown_mask & object_mask).astype(np.uint8)\n","\n","        conf_map = conf_score.squeeze().cpu().numpy()\n","        obstacle_score = objectness.squeeze().cpu().numpy() * nonconformity.squeeze().cpu().numpy()\n","\n","    if should_save:\n","        if is_top:\n","            save_dir = os.path.join(save_top_root, name)\n","        elif is_worst:\n","            save_dir = os.path.join(save_worst_root, name)\n","        else:\n","            save_dir = os.path.join(save_dir_root, name)\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","        d(\"Saving in:\", save_dir)\n","\n","        rgb_img.save(os.path.join(save_dir, \"rgb.png\"))\n","\n","        fig, ax = plt.subplots(figsize=(6, 5))\n","        im = ax.imshow(conf_map, cmap=\"viridis\", vmin=0.0, vmax=1.0)\n","        ax.axis(\"off\")\n","        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","        cbar.set_label(\"Confidence scale\")\n","        plt.savefig(os.path.join(save_dir, \"confidence_map.png\"), dpi=200)\n","        plt.close()\n","\n","        fig, ax = plt.subplots(figsize=(6, 5))\n","        im = ax.imshow(obstacle_score, cmap=\"viridis_r\", vmin=0.0, vmax=1.0)\n","        ax.axis(\"off\")\n","        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","        cbar.set_label(\"Obstacle Score\")\n","        plt.savefig(os.path.join(save_dir, \"obstacle_score.png\"), dpi=200)\n","        plt.close()\n","\n","        if is_top or (not is_worst):\n","            Image.fromarray((gt_obstacle * 255).astype(np.uint8)).save(os.path.join(save_dir, \"gt_obstacle.png\"))\n","            Image.fromarray((unknown_mask * 255).astype(np.uint8)).save(os.path.join(save_dir, \"unknown_mask.png\"))\n","            Image.fromarray((object_mask * 255).astype(np.uint8)).save(os.path.join(save_dir, \"object_mask.png\"))\n","            Image.fromarray((obstacle_mask * 255).astype(np.uint8)).save(os.path.join(save_dir, \"obstacle_mask.png\"))\n"]},{"cell_type":"code","source":["\"\"\" #kept here for backup\n","  fig, axs = plt.subplots(1, 7, figsize=(42, 6))\n","  axs[0].imshow(rgb_img)\n","  axs[0].set_title(\"RGB Image\")\n","  axs[1].imshow(gt_obstacle, cmap=\"gray\")\n","  axs[1].set_title(\"GT Obstacle\")\n","  axs[2].imshow(unknown_mask, cmap=\"gray\")\n","  axs[2].set_title(\"Unknown Mask\")\n","  axs[3].imshow(object_mask, cmap=\"gray\")\n","  axs[3].set_title(\"Objectness Mask\")\n","  axs[4].imshow(obstacle_mask, cmap=\"gray\")\n","  axs[4].set_title(\"Obstacle = Unknown AND Object\")\n","  # CONFIDENCE MAP USING ONLY SOFTMAX\n","  im1 = axs[5].imshow(conf_map, cmap=\"viridis\", vmin=0.0, vmax=1.0)\n","  axs[5].set_title(\"Confidence Map (Max Softmax)\")\n","  cbar1 = fig.colorbar(im1, ax=axs[5], fraction=0.046, pad=0.04)\n","  cbar1.set_label(\"Confidence scale\")\n","  # CONFIDENCE MAP USING SOFTMAX AND SIGMOID HEAD COMBINED\n","  im2 = axs[6].imshow(obstacle_score, cmap=\"viridis_r\", vmin=0.0, vmax=1.0) #doing viridis\"_r\" in order to revert the behaviour of the viridis heatmap and return an image prone to be compared to the other confidence map\n","  axs[6].set_title(\"Obstacle Score = Objectness combined with Nonconformity\")\n","  cbar2 = fig.colorbar(im2, ax=axs[6], fraction=0.046, pad=0.04)\n","  cbar2.set_label(\"Obstacle Score\")\n","\n","  for ax in axs:\n","      ax.axis(\"off\")\n","  plt.suptitle(name, fontsize=18)\n","  plt.tight_layout()\n","  plt.show()\n","\"\"\""],"metadata":{"id":"6hqK7dPqywCG"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}