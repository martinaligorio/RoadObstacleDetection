{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAXlECRgu_VI"
      },
      "outputs": [],
      "source": [
        "#================================================\n",
        "#DEBUG TOGGLE SWITCH\n",
        "\n",
        "def d(*args, **kwargs):\n",
        "    if d.ON:\n",
        "        print(*args, **kwargs)\n",
        "\n",
        "d.ON = True          # <- module-local switch\n",
        "\n",
        "##example usage\n",
        "#d(\"Initial x shape:\", x.shape)\n",
        "#================================================\n",
        "if __name__ == \"__main__\":\n",
        "  try:\n",
        "    import segmentation_models_pytorch as smp\n",
        "  except ImportError:\n",
        "    !pip install -q segmentation_models_pytorch timm\n",
        "    import segmentation_models_pytorch as smp\n",
        "#============================================================0\n",
        "\n",
        "\n",
        "#================================================\n",
        "# NAVIGATION TO GET TO THE FOLDER WITH STUFF INSIDE\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/ProjectWorkspace/src\")\n",
        "#=================================================0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#=================================================\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from network.deeplab_dualhead import get_model\n",
        "from dataloader.cityscapes_dataloader import CityscapesDataset\n",
        "#========================================================================\n",
        "\n",
        "\n",
        "\n",
        "#========================================================================\n",
        "# PATHS SETTING\n",
        "calib_images_dir = \"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/Datasets/leftImg8bit_trainvaltest/leftImg8bit_trainvaltest/leftImg8bit/val\"\n",
        "calib_masks_dir = \"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/Datasets/leftImg8bit_trainvaltest/gtFine_trainvaltest/gtFine/val\"\n",
        "split_dir = \"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/ProjectWorkspace/splits\"\n",
        "\n",
        "with open(os.path.join(split_dir, \"calib_cp.txt\"), \"r\") as f:\n",
        "  calib_list = [line.strip() for line in f]\n",
        "#===========================================================================\n",
        "\n",
        "\n",
        "#============================================\n",
        "# TAKIN DATASET\n",
        "calib_dataset = CityscapesDataset(calib_images_dir, calib_masks_dir, calib_list, augment=False) #ofc augm was just for training\n",
        "calib_loader = DataLoader(calib_dataset, batch_size=1, shuffle=False, num_workers=2) #now i want data to be provided one at a time\n",
        "#==============================================\n",
        "\n",
        "\n",
        "#===============================================================\n",
        "# SETTING UP THE MODEL\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = get_model().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/ProjectWorkspace/ckpts/updated_loss_model.pth\"))\n",
        "model.eval()\n",
        "#===================================================================================0\n",
        "\n",
        "\n",
        "#====================================================================================\n",
        "# NON CONFORMITY SCORES COMPUTATION\n",
        "scores = []\n",
        "with torch.no_grad(): #deactivation of gradient tracking as well for non training purposes\n",
        "  for images, _, _ in tqdm(calib_loader):\n",
        "    images = images.to(device)\n",
        "    pred_softmax, _ = model(images)\n",
        "    pred_softmax = F.interpolate(pred_softmax, size=images.shape[-2:], mode=\"bilinear\", align_corners=False) #outpu has reduced dimension remember\n",
        "    max_probs = torch.max(torch.softmax(pred_softmax, dim=1), dim=1)[0] #takin max prob value for each px\n",
        "    nonconf = 1.0 - max_probs #non conformity score\n",
        "    scores.append(nonconf.cpu().numpy())\n",
        "\n",
        "scores = np.concatenate([s.flatten() for s in scores], axis=0) #take all the arrays in scores variable, flatten in 1D and merging in one array with all of em\n",
        "#====================================================================================\n",
        "\n",
        "\n",
        "\n",
        "#=========================================================================================\n",
        "# CONFORMAL CALIBRATION\n",
        "alpha = 0.15\n",
        "lambda_hat = np.quantile(scores, 1-alpha) #1-alpha to ensure the 97% of those values are under this treshold -> indicates how much uncertainty has THAT px if it goes over\n",
        "print(f\"Calibrated lambda_hat at alpha = {alpha}: {lambda_hat:.6f}\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/ProjectWorkspace/src/eval/lambda_hat_3rdattempt.txt\", \"w\") as f:\n",
        "  f.write(f\"{lambda_hat:.6f}\")\n",
        "  f.write(\"\\n\")\n",
        "#=========================================================================================\n",
        "\n",
        "\n",
        "\n",
        "##########################################################################################################\n",
        "# DUMMY TEST JUST WITH 5 PIXELS FROM FIRST IMAGE\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  sample_image, _, _ = calib_dataset[0]\n",
        "  sample_image = sample_image.unsqueeze(0).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pred_softmax, _ = model(sample_image)\n",
        "    pred_softmax = F.interpolate(pred_softmax, size=sample_image.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
        "    max_probs = torch.max(torch.softmax(pred_softmax, dim=1), dim=1)[0]\n",
        "    nonconf = 1.0 - max_probs\n",
        "\n",
        "  d(\"Image shape:\", sample_image.shape)\n",
        "  flat_scores = nonconf.view(-1)\n",
        "  d(\"First 5 non conformity scores:\", flat_scores[:5].cpu().numpy())\n",
        "\n",
        "  with open(\"/content/drive/MyDrive/MAGISTRALE/ANNO 1/Computer Vision/Project/RoadObstacleDetection/ProjectWorkspace/src/eval/lambda_hat_3rdattempt.txt\", \"r\") as f:\n",
        "    lambda_hat_loaded = float(f.readline().strip())\n",
        "\n",
        "  d(\"Loaded lambda_hat:\", lambda_hat_loaded)\n",
        "\n",
        "  exceed = flat_scores[:5] > lambda_hat_loaded\n",
        "  d(\"Let's see if these 5 pixels exceed lambda_hat\", exceed.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}