{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPakQns4FAXsR+nEvN0mykl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"I8LC7ab6_M7v"},"outputs":[],"source":["import os\n","import numpy as np\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset\n","import torchvision.transforms as T\n","\n","class LostAndFoundObstacleDataset(Dataset):\n","    def __init__(self, root, img_transform=None, mask_transform=None):\n","        \"\"\"\n","        Dataset for LostAndFound evaluation.\n","        Contains only object-level binary masks; class masks are not used.\n","\n","        Args:\n","            root (str): root path to LostAndFound dataset\n","            img_transform (callable): transform applied to RGB images\n","            mask_transform (callable): transform applied to binary masks\n","        \"\"\"\n","        self.img_dir = os.path.join(root, 'leftImg8bit')\n","        self.gt_dir = os.path.join(root, 'gtCoarse')\n","        self.img_transform = img_transform\n","        self.mask_transform = mask_transform\n","\n","        self.img_paths = []\n","        self.mask_paths = []\n","\n","        # Traverse subfolders (each sequence is in its own folder)\n","        for sequence in os.listdir(self.img_dir):\n","            img_seq_dir = os.path.join(self.img_dir, sequence)\n","            gt_seq_dir = os.path.join(self.gt_dir, sequence)\n","            for fname in os.listdir(img_seq_dir):\n","                if fname.endswith('_leftImg8bit.png'):\n","                    self.img_paths.append(os.path.join(img_seq_dir, fname))\n","                    label_fname = fname.replace('leftImg8bit', 'gtCoarse_labelIds')\n","                    self.mask_paths.append(os.path.join(gt_seq_dir, label_fname))\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Returns:\n","            dict: {\n","                'image': RGB input tensor,\n","                'object_mask': binary mask (1 = unknown object),\n","                'class_mask': tensor filled with 255 (ignored),\n","                'is_ood': True\n","            }\n","        \"\"\"\n","        # Load RGB image\n","        image = Image.open(self.img_paths[idx]).convert('RGB')\n","\n","        # Load coarse label mask\n","        mask = Image.open(self.mask_paths[idx])\n","        mask_np = np.array(mask)\n","\n","        # In LostAndFound, obstacle pixels have label == 1 (others == 0 or 255)\n","        object_mask = (mask_np == 1).astype(np.uint8)\n","        object_mask = torch.from_numpy(object_mask).long()\n","\n","        # Dummy class mask (ignored in evaluation)\n","        class_mask = torch.full_like(object_mask, fill_value=255)\n","\n","        # Apply transforms\n","        if self.img_transform:\n","            image = self.img_transform(image)\n","        else:\n","            image = T.ToTensor()(image)\n","\n","        if self.mask_transform:\n","            object_mask = self.mask_transform(object_mask.unsqueeze(0)).squeeze(0)\n","            class_mask = self.mask_transform(class_mask.unsqueeze(0)).squeeze(0)\n","\n","        return {\n","            'image': image,\n","            'class_mask': class_mask,      # ignored (255)\n","            'object_mask': object_mask,\n","            'is_ood': True\n","        }\n"]}]}